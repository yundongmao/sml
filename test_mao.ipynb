{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4867136\n",
      "2001\n"
     ]
    }
   ],
   "source": [
    "f = open(\"train.txt\")\n",
    "\n",
    "ll = []\n",
    "\n",
    "for line in f.readlines():\n",
    "    ll.append(line.split())\n",
    "s = set([v for c in ll for v in c])\n",
    "print(len(s))\n",
    "f.close()\n",
    "\n",
    "\n",
    "f = open(\"test-public.txt\")\n",
    "lltest = []\n",
    "for line in f.readlines():\n",
    "    lltest.append(line.split())\n",
    "print(len(lltest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node_list = list(s)\n",
    "    \n",
    "startset = set([c[0] for c in ll])\n",
    "\n",
    "line_number = {}\n",
    "for c in ll:\n",
    "    line_number[c[0]] = len(line_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = {}\n",
    "for c in ll:\n",
    "    m[c[0]] = set(c[1:])\n",
    "following = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m2 = {}\n",
    "for c in ll:\n",
    "    for v in c[1:]:\n",
    "        if v in m2:\n",
    "            m2[v].add(c[0])\n",
    "        else:\n",
    "            m2[v] = set([c[0]])\n",
    "followed = m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m3 = {}\n",
    "for c in ll:\n",
    "    temp = 1/float(len(c))\n",
    "    for v in c[1:]:\n",
    "        if v in m3:\n",
    "            m3[v][c[0]] = temp\n",
    "        else:\n",
    "            m3[v] = {}\n",
    "            m3[v][c[0]] = temp\n",
    "weightFollowed = m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "follewedLength= {}\n",
    "for c in m3.keys():\n",
    "    follewedLength[c] = sum([v*2 for v in m3[c].values()])**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19570\n",
      "20008\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "train_pos_list = []\n",
    "for l in ll:\n",
    "    for i in range(1,min(2,len(l))):\n",
    "        train_pos_list.append([1,l[0],l[i]])\n",
    "\n",
    "\n",
    "train_neg_list = []\n",
    "for l in ll:\n",
    "    if len(train_neg_list) > 20000:\n",
    "        break\n",
    "    for i in range(10):\n",
    "        temp = random.randint(0,len(node_list)-1)\n",
    "        if node_list[temp] not in m[l[0]]:\n",
    "            train_neg_list.append([1,l[0],node_list[temp]])\n",
    "print(len(train_pos_list))\n",
    "print(len(train_neg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate positive sample\n",
      "add nodes\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "file = open('train.txt', mode='r')\n",
    "train = dict()\n",
    "for line in file:\n",
    "    temp = line.split('\\t')\n",
    "    train[temp[0]] = temp[1:]\n",
    "\n",
    "    \n",
    "    \n",
    "#positive sample\n",
    "print('generate positive sample')\n",
    "new_train = set()\n",
    "for k, v in train.items():\n",
    "    for values in v:\n",
    "        new_train.add((int(k), int(values)))\n",
    "\n",
    "print('add nodes')\n",
    "G.add_edges_from(new_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_list_h = [[int(c[1]),int(c[2])] for c in train_pos_list]\n",
    "train_neg_list_h = [[int(c[1]),int(c[2])] for c in train_neg_list]\n",
    "test_list_h = [[int(c[1]),int(c[2])] for c in lltest[1:]]\n",
    "RA_train_positive_set = nx.resource_allocation_index(G, train_pos_list_h)\n",
    "RA_train_negative_set = nx.resource_allocation_index(G, train_neg_list_h)\n",
    "RA_test_set = nx.resource_allocation_index(G, test_list_h)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [p for u,v,p in RA_train_positive_set]\n",
    "temp2 = [p for u,v,p in RA_train_negative_set]\n",
    "temp3 = [p for u,v,p in RA_test_set]\n",
    "\n",
    "train_pos_list_5 = []\n",
    "for i in range(len(train_pos_list2)):\n",
    "    train_pos_list_5.append(train_pos_list2[i]+[temp[i]])\n",
    "\n",
    "train_neg_list_5 = []\n",
    "for i in range(len(train_neg_list2)):\n",
    "    train_neg_list_5.append(train_neg_list2[i]+[temp2[i]])\n",
    "    \n",
    "test_list_5 = []    \n",
    "for i in range(len(test_list2)):\n",
    "    test_list_5.append(test_list2[i]+[temp3[i]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AA_train_positive_set = nx.adamic_adar_index(G, train_pos_list_h)\n",
    "AA_train_negative_set = nx.adamic_adar_index(G, train_neg_list_h)\n",
    "AA_test_set = nx.adamic_adar_index(G, test_list_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [p for u,v,p in AA_train_positive_set]\n",
    "temp2 = [p for u,v,p in AA_train_negative_set]\n",
    "temp3 = [p for u,v,p in AA_test_set]\n",
    "\n",
    "for i in range(len(train_pos_list2)):\n",
    "    train_pos_list_5[i].append(temp[i])\n",
    "\n",
    "for i in range(len(train_neg_list2)):\n",
    "    train_neg_list_5[i].append(temp2[i])\n",
    "    \n",
    "for i in range(len(test_list2)):\n",
    "    test_list_5[i].append(temp3[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "JJ_train_positive_set = nx.jaccard_coefficient(G, train_pos_list_h)\n",
    "JJ_train_negative_set = nx.jaccard_coefficient(G, train_neg_list_h)\n",
    "JJ_test_set = nx.jaccard_coefficient(G, test_list_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = [p for u,v,p in JJ_train_positive_set]\n",
    "temp2 = [p for u,v,p in JJ_train_negative_set]\n",
    "temp3 = [p for u,v,p in JJ_test_set]\n",
    "\n",
    "for i in range(len(train_pos_list2)):\n",
    "    train_pos_list_5[i].append(temp[i])\n",
    "\n",
    "for i in range(len(train_neg_list2)):\n",
    "    train_neg_list_5[i].append(temp2[i])\n",
    "    \n",
    "for i in range(len(test_list2)):\n",
    "    test_list_5[i].append(temp3[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_list_6 = [[c[0],c[1],c[2],c[3],c[4] for c in train_pos_list_5]\n",
    "train_neg_list_6 = [[c[0],c[1],c[2],c[3],c[4] for c in train_neg_list_5]\n",
    "test_list_6 = [[c[0],c[1],c[2],c[3],c[4] for c in test_list_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in train_pos_list_5:\n",
    "    c.pop()\n",
    "\n",
    "for c in train_neg_list_5:\n",
    "    c.pop()\n",
    "    \n",
    "for c in test_list_5:\n",
    "    c.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateFeatures(dataList):\n",
    "    resultList1 = []\n",
    "    resultList2 = []\n",
    "    for i,c in enumerate(dataList[1:]):\n",
    "        if len(following[c[1]]) == 0:\n",
    "            continue\n",
    "        if i % 1000 == 0:\n",
    "            print(i)\n",
    "        temp3 = 0\n",
    "        temp2 = 0\n",
    "        for v in (set(m3[c[1]].keys())&set(m3[c[2]].keys())):\n",
    "            temp2 += m3[c[1]][v] * m3[c[2]][v]\n",
    "        temp3 += temp2 / follewedLength[c[1]] * follewedLength[c[2]]\n",
    "        resultList1.append([temp3])\n",
    "        temp3*=400\n",
    "\n",
    "        tempscore = 1/float(len(following[c[1]]))\n",
    "        temp2 = 0\n",
    "        temp4 = 0\n",
    "        for v1 in following[c[1]]:\n",
    "            if v1 not in following:\n",
    "                continue\n",
    "            if len(following[v1]) ==0:\n",
    "                continue\n",
    "            tempscore2 = 1/float(len(following[v1]))\n",
    "            for v2 in (following[v1] & set(m3[c[2]].keys())):\n",
    "                temp2+=tempscore2*m3[c[2]][v2]\n",
    "    #             if v2 not in following:\n",
    "    #                 continue\n",
    "    #             if len(following[v2]) ==0:\n",
    "    #                 continue\n",
    "    #             tempscore3 = 1/float(len(following[v2]))\n",
    "    #             temp22 = 0\n",
    "    #             for v3 in (following[v2] & set(m3[c[2]].keys())):\n",
    "    #                 temp22+=tempscore3*m3[c[2]][v3]\n",
    "    #             temp2+=tempscore2*temp22\n",
    "        temp4+= temp2*tempscore\n",
    "        temp3+=temp4\n",
    "        resultList1[-1].append(temp4)\n",
    "\n",
    "        temp4 = 0\n",
    "        for v in (following[c[1]] & set(m3[c[2]].keys())):\n",
    "            temp4+= tempscore*m3[c[2]][v]\n",
    "        temp3+=temp4\n",
    "        resultList1[-1].append(temp4)\n",
    "\n",
    "        temp4 = 0\n",
    "        if c[2] in following and c[1] in following[c[2]]:\n",
    "            temp4+= 1/float(len(following[c[2]]))\n",
    "        temp3+= temp4\n",
    "        resultList1[-1].append(temp4)\n",
    "        resultList2.append([temp3,i])\n",
    "    return resultList1,resultList2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "test_list2,temp = generateFeatures(lltest)\n",
    "train_pos_list2,temp = generateFeatures(train_pos_list)\n",
    "train_neg_list2,temp = generateFeatures(train_neg_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.00029578037648517907, 0.0004203028381854329, 0, 0.010297018215570252, 0.008064516129032258]\n"
     ]
    }
   ],
   "source": [
    "print(train_pos_list_6[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.450525   0.48298405 0.450525   ... 0.45052475 0.450525   0.450525  ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# LogisticRegression.fit()\n",
    "clf = LinearRegression()\n",
    "clf.fit(np.array(train_pos_list_6+train_neg_list_6),np.array([1]*len(train_pos_list_6)+[0]*len(train_neg_list_6)))\n",
    "\n",
    "label = clf.predict(test_list_6)\n",
    "print (label)\n",
    "\n",
    "f3 = open(\"result5-1.txt\",\"w\")\n",
    "f3.writelines(\"Id,Prediction\\n\")\n",
    "for i,c in enumerate(label):\n",
    "    f3.writelines(str(i+1)+\",\"+str(c)+\"\\n\")\n",
    "f3.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.55061904 0.44938096]\n",
      " [0.54447535 0.45552465]\n",
      " [0.55061905 0.44938095]\n",
      " ...\n",
      " [0.55061792 0.44938208]\n",
      " [0.55061905 0.44938095]\n",
      " [0.55061904 0.44938096]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# LogisticRegression.fit()\n",
    "clf = LogisticRegression()\n",
    "clf.fit(np.array(train_pos_list_6+train_neg_list_6),np.array([1]*len(train_pos_list_6)+[0]*len(train_neg_list_6)))\n",
    "\n",
    "label = clf.predict_proba(test_list_6)\n",
    "print (label)\n",
    "\n",
    "f3 = open(\"result5-1.txt\",\"w\")\n",
    "f3.writelines(\"Id,Prediction\\n\")\n",
    "for i,c in enumerate(label):\n",
    "    f3.writelines(str(i+1)+\",\"+str(c[1])+\"\\n\")\n",
    "f3.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6524032 0.3475968]\n",
      " [0.6524032 0.3475968]\n",
      " [0.6524032 0.3475968]\n",
      " ...\n",
      " [0.6524032 0.3475968]\n",
      " [0.6524032 0.3475968]\n",
      " [0.6524032 0.3475968]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# LogisticRegression.fit()\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(np.array(train_pos_list_6+train_neg_list_6),np.array([1]*len(train_pos_list_6)+[0]*len(train_neg_list_6)))\n",
    "\n",
    "label = clf.predict_proba(test_list_6)\n",
    "print (label)\n",
    "\n",
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier()\n",
    "MLPClassifier(solver='sgd', alpha=1e-5, hidden_layer_sizes=(20005, 3), random_state=1, learning_rate=0.001, max_iter=1000, shuffle=True)\n",
    "mlp.fit(np.array(train_pos_list_6+train_neg_list_6),np.array([1]*len(train_pos_list_6)+[0]*len(train_neg_list_6)))\n",
    "label = mlp.predict_proba(test_list_6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -2.48, time = 0.55s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -1.90, time = 0.88s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -1.53, time = 0.79s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -1.27, time = 0.79s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -1.09, time = 0.82s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -0.95, time = 0.78s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -0.85, time = 0.80s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -0.77, time = 0.84s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -0.71, time = 0.80s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -0.66, time = 0.84s\n",
      "[BernoulliRBM] Iteration 11, pseudo-likelihood = -0.61, time = 0.83s\n",
      "[BernoulliRBM] Iteration 12, pseudo-likelihood = -0.58, time = 0.79s\n",
      "[BernoulliRBM] Iteration 13, pseudo-likelihood = -0.55, time = 0.82s\n",
      "[BernoulliRBM] Iteration 14, pseudo-likelihood = -0.52, time = 0.80s\n",
      "[BernoulliRBM] Iteration 15, pseudo-likelihood = -0.50, time = 0.80s\n",
      "[BernoulliRBM] Iteration 16, pseudo-likelihood = -0.48, time = 0.80s\n",
      "[BernoulliRBM] Iteration 17, pseudo-likelihood = -0.46, time = 0.85s\n",
      "[BernoulliRBM] Iteration 18, pseudo-likelihood = -0.44, time = 0.80s\n",
      "[BernoulliRBM] Iteration 19, pseudo-likelihood = -0.43, time = 0.78s\n",
      "[BernoulliRBM] Iteration 20, pseudo-likelihood = -0.42, time = 0.87s\n",
      "[BernoulliRBM] Iteration 21, pseudo-likelihood = -0.40, time = 0.83s\n",
      "[BernoulliRBM] Iteration 22, pseudo-likelihood = -0.39, time = 0.81s\n",
      "[BernoulliRBM] Iteration 23, pseudo-likelihood = -0.38, time = 0.82s\n",
      "[BernoulliRBM] Iteration 24, pseudo-likelihood = -0.38, time = 0.83s\n",
      "[BernoulliRBM] Iteration 25, pseudo-likelihood = -0.37, time = 0.80s\n",
      "[BernoulliRBM] Iteration 26, pseudo-likelihood = -0.36, time = 0.79s\n",
      "[BernoulliRBM] Iteration 27, pseudo-likelihood = -0.36, time = 0.81s\n",
      "[BernoulliRBM] Iteration 28, pseudo-likelihood = -0.35, time = 0.80s\n",
      "[BernoulliRBM] Iteration 29, pseudo-likelihood = -0.34, time = 0.78s\n",
      "[BernoulliRBM] Iteration 30, pseudo-likelihood = -0.34, time = 0.82s\n",
      "[BernoulliRBM] Iteration 31, pseudo-likelihood = -0.33, time = 0.83s\n",
      "[BernoulliRBM] Iteration 32, pseudo-likelihood = -0.33, time = 0.85s\n",
      "[BernoulliRBM] Iteration 33, pseudo-likelihood = -0.33, time = 0.85s\n",
      "[BernoulliRBM] Iteration 34, pseudo-likelihood = -0.32, time = 0.84s\n",
      "[BernoulliRBM] Iteration 35, pseudo-likelihood = -0.32, time = 0.79s\n",
      "[BernoulliRBM] Iteration 36, pseudo-likelihood = -0.31, time = 0.80s\n",
      "[BernoulliRBM] Iteration 37, pseudo-likelihood = -0.31, time = 0.83s\n",
      "[BernoulliRBM] Iteration 38, pseudo-likelihood = -0.31, time = 0.83s\n",
      "[BernoulliRBM] Iteration 39, pseudo-likelihood = -0.30, time = 0.80s\n",
      "[BernoulliRBM] Iteration 40, pseudo-likelihood = -0.30, time = 0.79s\n",
      "[BernoulliRBM] Iteration 41, pseudo-likelihood = -0.30, time = 0.79s\n",
      "[BernoulliRBM] Iteration 42, pseudo-likelihood = -0.30, time = 0.81s\n",
      "[BernoulliRBM] Iteration 43, pseudo-likelihood = -0.29, time = 0.82s\n",
      "[BernoulliRBM] Iteration 44, pseudo-likelihood = -0.29, time = 0.80s\n",
      "[BernoulliRBM] Iteration 45, pseudo-likelihood = -0.29, time = 0.86s\n",
      "[BernoulliRBM] Iteration 46, pseudo-likelihood = -0.29, time = 0.81s\n",
      "[BernoulliRBM] Iteration 47, pseudo-likelihood = -0.29, time = 0.82s\n",
      "[BernoulliRBM] Iteration 48, pseudo-likelihood = -0.28, time = 0.81s\n",
      "[BernoulliRBM] Iteration 49, pseudo-likelihood = -0.28, time = 0.81s\n",
      "[BernoulliRBM] Iteration 50, pseudo-likelihood = -0.28, time = 0.82s\n",
      "[BernoulliRBM] Iteration 51, pseudo-likelihood = -0.28, time = 0.81s\n",
      "[BernoulliRBM] Iteration 52, pseudo-likelihood = -0.28, time = 0.80s\n",
      "[BernoulliRBM] Iteration 53, pseudo-likelihood = -0.28, time = 0.80s\n",
      "[BernoulliRBM] Iteration 54, pseudo-likelihood = -0.27, time = 0.81s\n",
      "[BernoulliRBM] Iteration 55, pseudo-likelihood = -0.27, time = 0.80s\n",
      "[BernoulliRBM] Iteration 56, pseudo-likelihood = -0.27, time = 0.78s\n",
      "[BernoulliRBM] Iteration 57, pseudo-likelihood = -0.27, time = 0.81s\n",
      "[BernoulliRBM] Iteration 58, pseudo-likelihood = -0.27, time = 0.80s\n",
      "[BernoulliRBM] Iteration 59, pseudo-likelihood = -0.27, time = 0.85s\n",
      "[BernoulliRBM] Iteration 60, pseudo-likelihood = -0.27, time = 0.84s\n",
      "[BernoulliRBM] Iteration 61, pseudo-likelihood = -0.27, time = 0.78s\n",
      "[BernoulliRBM] Iteration 62, pseudo-likelihood = -0.26, time = 0.84s\n",
      "[BernoulliRBM] Iteration 63, pseudo-likelihood = -0.26, time = 0.79s\n",
      "[BernoulliRBM] Iteration 64, pseudo-likelihood = -0.26, time = 0.81s\n",
      "[BernoulliRBM] Iteration 65, pseudo-likelihood = -0.26, time = 0.80s\n",
      "[BernoulliRBM] Iteration 66, pseudo-likelihood = -0.26, time = 0.79s\n",
      "[BernoulliRBM] Iteration 67, pseudo-likelihood = -0.26, time = 0.84s\n",
      "[BernoulliRBM] Iteration 68, pseudo-likelihood = -0.26, time = 0.80s\n",
      "[BernoulliRBM] Iteration 69, pseudo-likelihood = -0.26, time = 0.83s\n",
      "[BernoulliRBM] Iteration 70, pseudo-likelihood = -0.26, time = 0.84s\n",
      "[BernoulliRBM] Iteration 71, pseudo-likelihood = -0.26, time = 0.83s\n",
      "[BernoulliRBM] Iteration 72, pseudo-likelihood = -0.26, time = 0.83s\n",
      "[BernoulliRBM] Iteration 73, pseudo-likelihood = -0.25, time = 0.81s\n",
      "[BernoulliRBM] Iteration 74, pseudo-likelihood = -0.25, time = 0.82s\n",
      "[BernoulliRBM] Iteration 75, pseudo-likelihood = -0.25, time = 0.82s\n",
      "[BernoulliRBM] Iteration 76, pseudo-likelihood = -0.25, time = 0.83s\n",
      "[BernoulliRBM] Iteration 77, pseudo-likelihood = -0.25, time = 0.79s\n",
      "[BernoulliRBM] Iteration 78, pseudo-likelihood = -0.25, time = 0.85s\n",
      "[BernoulliRBM] Iteration 79, pseudo-likelihood = -0.25, time = 0.85s\n",
      "[BernoulliRBM] Iteration 80, pseudo-likelihood = -0.25, time = 0.81s\n",
      "[BernoulliRBM] Iteration 81, pseudo-likelihood = -0.25, time = 0.82s\n",
      "[BernoulliRBM] Iteration 82, pseudo-likelihood = -0.25, time = 0.79s\n",
      "[BernoulliRBM] Iteration 83, pseudo-likelihood = -0.25, time = 0.80s\n",
      "[BernoulliRBM] Iteration 84, pseudo-likelihood = -0.25, time = 0.81s\n",
      "[BernoulliRBM] Iteration 85, pseudo-likelihood = -0.25, time = 0.81s\n",
      "[BernoulliRBM] Iteration 86, pseudo-likelihood = -0.25, time = 0.81s\n",
      "[BernoulliRBM] Iteration 87, pseudo-likelihood = -0.25, time = 0.83s\n",
      "[BernoulliRBM] Iteration 88, pseudo-likelihood = -0.25, time = 0.83s\n",
      "[BernoulliRBM] Iteration 89, pseudo-likelihood = -0.24, time = 0.80s\n",
      "[BernoulliRBM] Iteration 90, pseudo-likelihood = -0.24, time = 0.79s\n",
      "[BernoulliRBM] Iteration 91, pseudo-likelihood = -0.24, time = 0.80s\n",
      "[BernoulliRBM] Iteration 92, pseudo-likelihood = -0.24, time = 0.78s\n",
      "[BernoulliRBM] Iteration 93, pseudo-likelihood = -0.24, time = 0.77s\n",
      "[BernoulliRBM] Iteration 94, pseudo-likelihood = -0.24, time = 0.78s\n",
      "[BernoulliRBM] Iteration 95, pseudo-likelihood = -0.24, time = 0.78s\n",
      "[BernoulliRBM] Iteration 96, pseudo-likelihood = -0.24, time = 0.78s\n",
      "[BernoulliRBM] Iteration 97, pseudo-likelihood = -0.24, time = 0.77s\n",
      "[BernoulliRBM] Iteration 98, pseudo-likelihood = -0.24, time = 0.78s\n",
      "[BernoulliRBM] Iteration 99, pseudo-likelihood = -0.24, time = 0.77s\n",
      "[BernoulliRBM] Iteration 100, pseudo-likelihood = -0.24, time = 0.78s\n",
      "[BernoulliRBM] Iteration 101, pseudo-likelihood = -0.24, time = 0.78s\n",
      "[BernoulliRBM] Iteration 102, pseudo-likelihood = -0.24, time = 0.83s\n",
      "[BernoulliRBM] Iteration 103, pseudo-likelihood = -0.24, time = 0.85s\n",
      "[BernoulliRBM] Iteration 104, pseudo-likelihood = -0.24, time = 0.80s\n",
      "[BernoulliRBM] Iteration 105, pseudo-likelihood = -0.24, time = 0.77s\n",
      "[BernoulliRBM] Iteration 106, pseudo-likelihood = -0.24, time = 0.79s\n",
      "[BernoulliRBM] Iteration 107, pseudo-likelihood = -0.24, time = 0.79s\n",
      "[BernoulliRBM] Iteration 108, pseudo-likelihood = -0.24, time = 0.77s\n",
      "[BernoulliRBM] Iteration 109, pseudo-likelihood = -0.24, time = 0.80s\n",
      "[BernoulliRBM] Iteration 110, pseudo-likelihood = -0.24, time = 0.80s\n",
      "[BernoulliRBM] Iteration 111, pseudo-likelihood = -0.24, time = 0.78s\n",
      "[BernoulliRBM] Iteration 112, pseudo-likelihood = -0.24, time = 0.81s\n",
      "[BernoulliRBM] Iteration 113, pseudo-likelihood = -0.24, time = 0.82s\n",
      "[BernoulliRBM] Iteration 114, pseudo-likelihood = -0.24, time = 0.78s\n",
      "[BernoulliRBM] Iteration 115, pseudo-likelihood = -0.23, time = 0.80s\n",
      "[BernoulliRBM] Iteration 116, pseudo-likelihood = -0.23, time = 0.79s\n",
      "[BernoulliRBM] Iteration 117, pseudo-likelihood = -0.23, time = 0.79s\n",
      "[BernoulliRBM] Iteration 118, pseudo-likelihood = -0.23, time = 0.80s\n",
      "[BernoulliRBM] Iteration 119, pseudo-likelihood = -0.23, time = 0.81s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BernoulliRBM] Iteration 120, pseudo-likelihood = -0.23, time = 0.79s\n",
      "[BernoulliRBM] Iteration 121, pseudo-likelihood = -0.23, time = 0.82s\n",
      "[BernoulliRBM] Iteration 122, pseudo-likelihood = -0.23, time = 0.79s\n",
      "[BernoulliRBM] Iteration 123, pseudo-likelihood = -0.23, time = 0.79s\n",
      "[BernoulliRBM] Iteration 124, pseudo-likelihood = -0.23, time = 0.80s\n",
      "[BernoulliRBM] Iteration 125, pseudo-likelihood = -0.23, time = 0.80s\n",
      "[BernoulliRBM] Iteration 126, pseudo-likelihood = -0.23, time = 0.83s\n",
      "[BernoulliRBM] Iteration 127, pseudo-likelihood = -0.23, time = 0.84s\n",
      "[BernoulliRBM] Iteration 128, pseudo-likelihood = -0.23, time = 0.87s\n",
      "[BernoulliRBM] Iteration 129, pseudo-likelihood = -0.23, time = 0.81s\n",
      "[BernoulliRBM] Iteration 130, pseudo-likelihood = -0.23, time = 0.82s\n",
      "[BernoulliRBM] Iteration 131, pseudo-likelihood = -0.23, time = 0.80s\n",
      "[BernoulliRBM] Iteration 132, pseudo-likelihood = -0.23, time = 0.83s\n",
      "[BernoulliRBM] Iteration 133, pseudo-likelihood = -0.23, time = 0.86s\n",
      "[BernoulliRBM] Iteration 134, pseudo-likelihood = -0.23, time = 0.87s\n",
      "[BernoulliRBM] Iteration 135, pseudo-likelihood = -0.23, time = 0.78s\n",
      "[BernoulliRBM] Iteration 136, pseudo-likelihood = -0.23, time = 0.78s\n",
      "[BernoulliRBM] Iteration 137, pseudo-likelihood = -0.23, time = 0.83s\n",
      "[BernoulliRBM] Iteration 138, pseudo-likelihood = -0.23, time = 0.83s\n",
      "[BernoulliRBM] Iteration 139, pseudo-likelihood = -0.23, time = 0.79s\n",
      "[BernoulliRBM] Iteration 140, pseudo-likelihood = -0.23, time = 0.82s\n",
      "[BernoulliRBM] Iteration 141, pseudo-likelihood = -0.23, time = 0.89s\n",
      "[BernoulliRBM] Iteration 142, pseudo-likelihood = -0.23, time = 0.86s\n",
      "[BernoulliRBM] Iteration 143, pseudo-likelihood = -0.23, time = 0.83s\n",
      "[BernoulliRBM] Iteration 144, pseudo-likelihood = -0.23, time = 0.83s\n",
      "[BernoulliRBM] Iteration 145, pseudo-likelihood = -0.23, time = 0.82s\n",
      "[BernoulliRBM] Iteration 146, pseudo-likelihood = -0.23, time = 0.87s\n",
      "[BernoulliRBM] Iteration 147, pseudo-likelihood = -0.23, time = 0.83s\n",
      "[BernoulliRBM] Iteration 148, pseudo-likelihood = -0.23, time = 0.83s\n",
      "[BernoulliRBM] Iteration 149, pseudo-likelihood = -0.23, time = 0.86s\n",
      "[BernoulliRBM] Iteration 150, pseudo-likelihood = -0.23, time = 0.83s\n",
      "[BernoulliRBM] Iteration 151, pseudo-likelihood = -0.23, time = 0.81s\n",
      "[BernoulliRBM] Iteration 152, pseudo-likelihood = -0.23, time = 0.81s\n",
      "[BernoulliRBM] Iteration 153, pseudo-likelihood = -0.23, time = 0.80s\n",
      "[BernoulliRBM] Iteration 154, pseudo-likelihood = -0.23, time = 0.82s\n",
      "[BernoulliRBM] Iteration 155, pseudo-likelihood = -0.23, time = 0.83s\n",
      "[BernoulliRBM] Iteration 156, pseudo-likelihood = -0.23, time = 0.84s\n",
      "[BernoulliRBM] Iteration 157, pseudo-likelihood = -0.23, time = 0.84s\n",
      "[BernoulliRBM] Iteration 158, pseudo-likelihood = -0.23, time = 0.82s\n",
      "[BernoulliRBM] Iteration 159, pseudo-likelihood = -0.23, time = 0.86s\n",
      "[BernoulliRBM] Iteration 160, pseudo-likelihood = -0.22, time = 0.87s\n",
      "[BernoulliRBM] Iteration 161, pseudo-likelihood = -0.22, time = 0.88s\n",
      "[BernoulliRBM] Iteration 162, pseudo-likelihood = -0.22, time = 0.84s\n",
      "[BernoulliRBM] Iteration 163, pseudo-likelihood = -0.22, time = 0.86s\n",
      "[BernoulliRBM] Iteration 164, pseudo-likelihood = -0.22, time = 0.88s\n",
      "[BernoulliRBM] Iteration 165, pseudo-likelihood = -0.22, time = 0.83s\n",
      "[BernoulliRBM] Iteration 166, pseudo-likelihood = -0.22, time = 0.86s\n",
      "[BernoulliRBM] Iteration 167, pseudo-likelihood = -0.22, time = 0.88s\n",
      "[BernoulliRBM] Iteration 168, pseudo-likelihood = -0.22, time = 0.90s\n",
      "[BernoulliRBM] Iteration 169, pseudo-likelihood = -0.22, time = 0.95s\n",
      "[BernoulliRBM] Iteration 170, pseudo-likelihood = -0.22, time = 0.89s\n",
      "[BernoulliRBM] Iteration 171, pseudo-likelihood = -0.22, time = 0.83s\n",
      "[BernoulliRBM] Iteration 172, pseudo-likelihood = -0.22, time = 0.80s\n",
      "[BernoulliRBM] Iteration 173, pseudo-likelihood = -0.22, time = 0.85s\n",
      "[BernoulliRBM] Iteration 174, pseudo-likelihood = -0.22, time = 0.87s\n",
      "[BernoulliRBM] Iteration 175, pseudo-likelihood = -0.22, time = 0.82s\n",
      "[BernoulliRBM] Iteration 176, pseudo-likelihood = -0.22, time = 0.84s\n",
      "[BernoulliRBM] Iteration 177, pseudo-likelihood = -0.22, time = 0.82s\n",
      "[BernoulliRBM] Iteration 178, pseudo-likelihood = -0.22, time = 0.86s\n",
      "[BernoulliRBM] Iteration 179, pseudo-likelihood = -0.22, time = 0.82s\n",
      "[BernoulliRBM] Iteration 180, pseudo-likelihood = -0.22, time = 0.84s\n",
      "[BernoulliRBM] Iteration 181, pseudo-likelihood = -0.22, time = 0.85s\n",
      "[BernoulliRBM] Iteration 182, pseudo-likelihood = -0.22, time = 0.82s\n",
      "[BernoulliRBM] Iteration 183, pseudo-likelihood = -0.22, time = 0.85s\n",
      "[BernoulliRBM] Iteration 184, pseudo-likelihood = -0.22, time = 0.86s\n",
      "[BernoulliRBM] Iteration 185, pseudo-likelihood = -0.22, time = 0.83s\n",
      "[BernoulliRBM] Iteration 186, pseudo-likelihood = -0.22, time = 0.84s\n",
      "[BernoulliRBM] Iteration 187, pseudo-likelihood = -0.22, time = 0.89s\n",
      "[BernoulliRBM] Iteration 188, pseudo-likelihood = -0.22, time = 0.85s\n",
      "[BernoulliRBM] Iteration 189, pseudo-likelihood = -0.22, time = 0.83s\n",
      "[BernoulliRBM] Iteration 190, pseudo-likelihood = -0.22, time = 0.79s\n",
      "[BernoulliRBM] Iteration 191, pseudo-likelihood = -0.22, time = 0.81s\n",
      "[BernoulliRBM] Iteration 192, pseudo-likelihood = -0.22, time = 0.80s\n",
      "[BernoulliRBM] Iteration 193, pseudo-likelihood = -0.22, time = 0.82s\n",
      "[BernoulliRBM] Iteration 194, pseudo-likelihood = -0.22, time = 0.83s\n",
      "[BernoulliRBM] Iteration 195, pseudo-likelihood = -0.22, time = 0.85s\n",
      "[BernoulliRBM] Iteration 196, pseudo-likelihood = -0.22, time = 0.80s\n",
      "[BernoulliRBM] Iteration 197, pseudo-likelihood = -0.22, time = 0.79s\n",
      "[BernoulliRBM] Iteration 198, pseudo-likelihood = -0.22, time = 0.81s\n",
      "[BernoulliRBM] Iteration 199, pseudo-likelihood = -0.22, time = 0.81s\n",
      "[BernoulliRBM] Iteration 200, pseudo-likelihood = -0.22, time = 0.82s\n",
      "[[0.6002849  0.3997151 ]\n",
      " [0.57316395 0.42683605]\n",
      " [0.60028525 0.39971475]\n",
      " ...\n",
      " [0.6002487  0.3997513 ]\n",
      " [0.60028526 0.39971474]\n",
      " [0.600285   0.399715  ]]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.neural_network import BernoulliRBM\n",
    "# clf = BernoulliRBM()\n",
    "# clf.fit(np.array(train_pos_list3+train_neg_list3),np.array([1]*len(train_pos_list3)+[0]*len(train_neg_list3)))\n",
    "\n",
    "# label = clf.predict(test444)\n",
    "# print len(label)\n",
    "\n",
    "\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Models we will use\n",
    "logistic = LogisticRegression()\n",
    "rbm = BernoulliRBM(random_state=0, verbose=True)\n",
    "\n",
    "classifier = Pipeline(steps=[('rbm', rbm), ('logistic', logistic)])\n",
    "\n",
    "# #############################################################################\n",
    "# Training\n",
    "\n",
    "# Hyper-parameters. These were set by cross-validation,\n",
    "# using a GridSearchCV. Here we are not performing cross-validation to\n",
    "# save time.\n",
    "rbm.learning_rate = 0.00001\n",
    "rbm.n_iter = 200\n",
    "# More components tend to give better prediction performance, but larger\n",
    "# fitting time\n",
    "rbm.n_components = 100\n",
    "logistic.C = 6000.0\n",
    "\n",
    "# Training RBM-Logistic Pipeline\n",
    "classifier.fit(np.array(train_pos_list_5+train_neg_list_5),np.array([1]*len(train_pos_list_5)+[0]*len(train_neg_list_5)))\n",
    "\n",
    "# Training Logistic regression\n",
    "logistic_classifier = LogisticRegression(C=100.0)\n",
    "logistic_classifier.fit(np.array(train_pos_list_5+train_neg_list_5),np.array([1]*len(train_pos_list_5)+[0]*len(train_neg_list_5)))\n",
    "\n",
    "label = classifier.predict_proba(test_list_5)\n",
    "print (label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f3 = open(\"result5-1.txt\",\"w\")\n",
    "f3.writelines(\"Id,Prediction\\n\")\n",
    "for i,c in enumerate(label):\n",
    "    f3.writelines(str(i+1)+\",\"+str(c)+\"\\n\")\n",
    "f3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPath(s,e):\n",
    "    if e in following[s]:\n",
    "        return 1\n",
    "    if len(following[s]) == 0:\n",
    "        return 1000\n",
    "    tempset = set()\n",
    "    pre = set([s])\n",
    "    count = 0\n",
    "    while len(pre)>0:\n",
    "        count+=1\n",
    "        tempset2 = set()\n",
    "        for c in pre:\n",
    "            if c not in following:\n",
    "                continue\n",
    "            if len(following[c]) == 0:\n",
    "                continue\n",
    "            tempset2 |= following[c]\n",
    "        pre = tempset2 - tempset\n",
    "        tempset |= tempset2\n",
    "        if e in pre:\n",
    "            return count\n",
    "        if count > 4:\n",
    "            break\n",
    "    return 1000        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
